#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GetQuickerç”¨æˆ·åŠ¨ä½œæ•°æ®ç»Ÿè®¡å·¥å…·
è·å–ç”¨æˆ·æ‰€æœ‰å…¬å¼€åŠ¨ä½œæ•°æ®å¹¶ç»Ÿè®¡ç‚¹èµæ€»æ•°
"""

import requests
import json
import sys
import logging
import time
import pandas as pd
from lxml import html
from typing import Dict, List, Optional, Tuple
from urllib.parse import urljoin


def setup_logger(debug: bool = False) -> logging.Logger:
    """
    è®¾ç½®æ—¥å¿—è®°å½•å™¨
    
    Args:
        debug (bool): æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
    
    Returns:
        logging.Logger: é…ç½®å¥½çš„æ—¥å¿—è®°å½•å™¨
    """
    logger = logging.getLogger('getquicker_actions_stats')
    logger.setLevel(logging.DEBUG if debug else logging.INFO)
    
    # æ¸…é™¤ç°æœ‰çš„å¤„ç†å™¨
    logger.handlers.clear()
    
    # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG if debug else logging.INFO)
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    if debug:
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
    else:
        formatter = logging.Formatter('%(message)s')
    
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger


def get_page_content(url: str, logger: logging.Logger) -> Optional[str]:
    """
    è·å–é¡µé¢HTMLå†…å®¹
    
    Args:
        url (str): ç›®æ ‡URL
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    
    Returns:
        Optional[str]: é¡µé¢HTMLå†…å®¹ï¼Œå¤±è´¥è¿”å›None
    """
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',
        'Referer': 'https://getquicker.net/Share',
    }
    
    try:
        logger.debug(f"æ­£åœ¨è®¿é—®: {url}")
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            logger.debug(f"âœ… æˆåŠŸè·å–é¡µé¢ï¼çŠ¶æ€ç : {response.status_code}")
            return response.text
        else:
            logger.error(f"âŒ è·å–é¡µé¢å¤±è´¥ï¼çŠ¶æ€ç : {response.status_code}")
            return None
            
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ è¯·æ±‚å¼‚å¸¸: {e}")
        return None


def extract_actions_using_pandas(html_content: str, logger: logging.Logger) -> List[Dict[str, any]]:
    """
    ä½¿ç”¨pandasè§£æHTMLè¡¨æ ¼ä¸­çš„åŠ¨ä½œæ•°æ®
    
    Args:
        html_content (str): é¡µé¢HTMLå†…å®¹
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    
    Returns:
        List[Dict[str, any]]: åŠ¨ä½œæ•°æ®åˆ—è¡¨
    """
    try:
        # ä½¿ç”¨pandasè¯»å–HTMLè¡¨æ ¼
        from io import StringIO
        tables = pd.read_html(StringIO(html_content))
        
        if not tables:
            logger.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•è¡¨æ ¼")
            return []
        
        # æ‰¾åˆ°åŠ¨ä½œè¡¨æ ¼ï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªè¡¨æ ¼ï¼‰
        action_table = tables[0]
        logger.info(f"âœ… æ‰¾åˆ°è¡¨æ ¼ï¼ŒåŒ…å« {len(action_table)} è¡Œæ•°æ®")
        
        # æ˜¾ç¤ºè¡¨æ ¼ç»“æ„
        logger.debug(f"è¡¨æ ¼åˆ—å: {list(action_table.columns)}")
        logger.debug(f"è¡¨æ ¼å½¢çŠ¶: {action_table.shape}")
        
        actions = []
        
        # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
        for index, row in action_table.iterrows():
            try:
                action_data = {}
                
                # æ ¹æ®å®é™…è¡¨æ ¼ç»“æ„è°ƒæ•´åˆ—æ˜ å°„
                # æ ¹æ®ä¹‹å‰çš„è°ƒè¯•ç»“æœï¼Œè¡¨æ ¼ç»“æ„æ˜¯ï¼š
                # ç¬¬1åˆ—: ç©º
                # ç¬¬2åˆ—: åç§°
                # ç¬¬3åˆ—: é€‚ç”¨äº
                # ç¬¬4åˆ—: åˆ†äº«äºº
                # ç¬¬5åˆ—: å¤§å°
                # ç¬¬6åˆ—: è·èµï¼ˆç‚¹èµæ•°ï¼‰
                # ç¬¬7åˆ—: ç”¨æˆ·ï¼ˆä¸‹è½½æ•°ï¼‰
                # ç¬¬8åˆ—: é¢‘åº¦
                
                if len(row) >= 8:
                    # è·å–å®Œæ•´çš„åç§°å­—æ®µï¼ˆåŒ…å«åŠ¨ä½œåç§°å’Œæè¿°ï¼‰
                    full_name = str(row.iloc[1]) if pd.notna(row.iloc[1]) else ''
                    
                    # å°è¯•åˆ†ç¦»åŠ¨ä½œåç§°å’Œæè¿°
                    # é€šå¸¸åŠ¨ä½œåç§°å’Œæè¿°ç”¨ç©ºæ ¼åˆ†éš”ï¼Œæè¿°éƒ¨åˆ†åŒ…å«æ›´å¤šæ–‡å­—
                    name_parts = full_name.split('  ', 1)  # æœ€å¤šåˆ†å‰²ä¸€æ¬¡
                    if len(name_parts) > 1:
                        action_data['name'] = name_parts[0].strip()
                        action_data['description'] = name_parts[1].strip()
                    else:
                        action_data['name'] = full_name.strip()
                        action_data['description'] = ''
                    
                    action_data['applicable'] = str(row.iloc[2]) if pd.notna(row.iloc[2]) else ''
                    action_data['author'] = str(row.iloc[3]) if pd.notna(row.iloc[3]) else ''
                    action_data['size'] = str(row.iloc[4]) if pd.notna(row.iloc[4]) else ''
                    
                    # ç‚¹èµæ•°ï¼ˆç¬¬6åˆ—ï¼‰
                    likes_value = row.iloc[5]
                    try:
                        if pd.notna(likes_value):
                            # å¤„ç†æµ®ç‚¹æ•°æˆ–æ•´æ•°
                            if isinstance(likes_value, (int, float)):
                                action_data['likes'] = int(likes_value)
                            else:
                                likes_text = str(likes_value).strip()
                                # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°å†è½¬ä¸ºæ•´æ•°
                                action_data['likes'] = int(float(likes_text))
                        else:
                            action_data['likes'] = 0
                    except (ValueError, TypeError):
                        action_data['likes'] = 0
                    
                    # ä¸‹è½½æ•°ï¼ˆç¬¬7åˆ—ï¼‰
                    downloads_value = row.iloc[6]
                    try:
                        if pd.notna(downloads_value):
                            # å¤„ç†æµ®ç‚¹æ•°æˆ–æ•´æ•°
                            if isinstance(downloads_value, (int, float)):
                                action_data['downloads'] = int(downloads_value)
                            else:
                                downloads_text = str(downloads_value).strip()
                                # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°å†è½¬ä¸ºæ•´æ•°
                                action_data['downloads'] = int(float(downloads_text))
                        else:
                            action_data['downloads'] = 0
                    except (ValueError, TypeError):
                        action_data['downloads'] = 0
                    
                    # é¢‘åº¦ï¼ˆç¬¬8åˆ—ï¼‰
                    action_data['frequency'] = str(row.iloc[7]) if pd.notna(row.iloc[7]) else ''
                    
                    # è¿‡æ»¤æ‰è¡¨å¤´è¡Œï¼ˆé€šå¸¸åŒ…å«"åç§°"ã€"é€‚ç”¨äº"ç­‰ï¼‰
                    if not any(keyword in action_data['name'] for keyword in ['åç§°', 'é€‚ç”¨äº', 'åˆ†äº«äºº']):
                        actions.append(action_data)
                        logger.debug(f"æå–åŠ¨ä½œ: {action_data['name']} - ç‚¹èµ: {action_data['likes']}")
                
            except Exception as e:
                logger.debug(f"å¤„ç†ç¬¬ {index+1} è¡Œæ—¶å‡ºé”™: {e}")
                continue
        
        logger.info(f"âœ… æˆåŠŸæå– {len(actions)} ä¸ªåŠ¨ä½œæ•°æ®")
        return actions
        
    except Exception as e:
        logger.error(f"âŒ ä½¿ç”¨pandasè§£æè¡¨æ ¼æ—¶å‡ºé”™: {e}")
        return []


def extract_actions_using_lxml(html_content: str, logger: logging.Logger) -> List[Dict[str, any]]:
    """
    ä½¿ç”¨lxmlè§£æHTMLè¡¨æ ¼ä¸­çš„åŠ¨ä½œæ•°æ®ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰
    
    Args:
        html_content (str): é¡µé¢HTMLå†…å®¹
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    
    Returns:
        List[Dict[str, any]]: åŠ¨ä½œæ•°æ®åˆ—è¡¨
    """
    try:
        # ä½¿ç”¨lxmlè§£æHTML
        tree = html.fromstring(html_content)
        
        # æŸ¥æ‰¾è¡¨æ ¼
        tables = tree.xpath('//table[@class="table table-bordered table-sm table-hover"]')
        
        if not tables:
            logger.warning("âŒ æœªæ‰¾åˆ°åŠ¨ä½œè¡¨æ ¼")
            return []
        
        table = tables[0]
        actions = []
        
        # æŸ¥æ‰¾æ‰€æœ‰è¡Œ
        rows = table.xpath('.//tr')
        logger.info(f"æ‰¾åˆ° {len(rows)} è¡Œæ•°æ®")
        
        for i, row in enumerate(rows):
            try:
                # è·å–æ‰€æœ‰å•å…ƒæ ¼
                cells = row.xpath('.//td | .//th')
                
                if len(cells) >= 8:
                    action_data = {}
                    
                    # æå–æ–‡æœ¬å†…å®¹
                    cell_texts = [cell.text_content().strip() for cell in cells]
                    
                    # è·å–å®Œæ•´çš„åç§°å­—æ®µï¼ˆåŒ…å«åŠ¨ä½œåç§°å’Œæè¿°ï¼‰
                    full_name = cell_texts[1] if len(cell_texts) > 1 else ''
                    
                    # å°è¯•åˆ†ç¦»åŠ¨ä½œåç§°å’Œæè¿°
                    name_parts = full_name.split('  ', 1)  # æœ€å¤šåˆ†å‰²ä¸€æ¬¡
                    if len(name_parts) > 1:
                        action_data['name'] = name_parts[0].strip()
                        action_data['description'] = name_parts[1].strip()
                    else:
                        action_data['name'] = full_name.strip()
                        action_data['description'] = ''
                    
                    action_data['applicable'] = cell_texts[2] if len(cell_texts) > 2 else ''
                    action_data['author'] = cell_texts[3] if len(cell_texts) > 3 else ''
                    action_data['size'] = cell_texts[4] if len(cell_texts) > 4 else ''
                    
                    # ç‚¹èµæ•°
                    likes_text = cell_texts[5] if len(cell_texts) > 5 else '0'
                    try:
                        if likes_text and likes_text.strip():
                            # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°å†è½¬ä¸ºæ•´æ•°
                            action_data['likes'] = int(float(likes_text))
                        else:
                            action_data['likes'] = 0
                    except (ValueError, TypeError):
                        action_data['likes'] = 0
                    
                    # ä¸‹è½½æ•°
                    downloads_text = cell_texts[6] if len(cell_texts) > 6 else '0'
                    try:
                        if downloads_text and downloads_text.strip():
                            # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°å†è½¬ä¸ºæ•´æ•°
                            action_data['downloads'] = int(float(downloads_text))
                        else:
                            action_data['downloads'] = 0
                    except (ValueError, TypeError):
                        action_data['downloads'] = 0
                    
                    # é¢‘åº¦
                    action_data['frequency'] = cell_texts[7] if len(cell_texts) > 7 else ''
                    
                    # è¿‡æ»¤æ‰è¡¨å¤´è¡Œ
                    if not any(keyword in action_data['name'] for keyword in ['åç§°', 'é€‚ç”¨äº', 'åˆ†äº«äºº']):
                        actions.append(action_data)
                        logger.debug(f"æå–åŠ¨ä½œ: {action_data['name']} - ç‚¹èµ: {action_data['likes']}")
                
            except Exception as e:
                logger.debug(f"å¤„ç†ç¬¬ {i+1} è¡Œæ—¶å‡ºé”™: {e}")
                continue
        
        logger.info(f"âœ… æˆåŠŸæå– {len(actions)} ä¸ªåŠ¨ä½œæ•°æ®")
        return actions
        
    except Exception as e:
        logger.error(f"âŒ ä½¿ç”¨lxmlè§£æè¡¨æ ¼æ—¶å‡ºé”™: {e}")
        return []


def get_total_pages(html_content: str, logger: logging.Logger) -> int:
    """
    è·å–æ€»é¡µæ•°
    
    Args:
        html_content (str): é¡µé¢HTMLå†…å®¹
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    
    Returns:
        int: æ€»é¡µæ•°ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›1
    """
    try:
        tree = html.fromstring(html_content)
        
        # æŸ¥æ‰¾åˆ†é¡µå¯¼èˆªä¸­çš„é¡µç é“¾æ¥
        page_links = tree.xpath('//nav//ul//li/a/text()')
        max_page = 1
        
        for link_text in page_links:
            try:
                if link_text.strip().isdigit():
                    page_num = int(link_text.strip())
                    max_page = max(max_page, page_num)
            except ValueError:
                continue
        
        logger.info(f"âœ… æ£€æµ‹åˆ°æ€»é¡µæ•°: {max_page}")
        return max_page
        
    except Exception as e:
        logger.debug(f"è·å–æ€»é¡µæ•°æ—¶å‡ºé”™: {e}")
        return 1


def get_all_user_actions(user_id: str, logger: logging.Logger) -> Tuple[List[Dict[str, any]], Dict[str, any]]:
    """
    è·å–ç”¨æˆ·æ‰€æœ‰å…¬å¼€åŠ¨ä½œæ•°æ®
    
    Args:
        user_id (str): ç”¨æˆ·ID
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    
    Returns:
        Tuple[List[Dict[str, any]], Dict[str, any]]: (åŠ¨ä½œåˆ—è¡¨, ç»Ÿè®¡ä¿¡æ¯)
    """
    base_url = f"https://getquicker.net/User/Actions/{user_id}"
    all_actions = []
    stats = {
        'total_actions': 0,
        'total_likes': 0,
        'total_downloads': 0,
        'total_pages': 0,
        'avg_likes': 0,
        'avg_downloads': 0
    }
    
    # è·å–ç¬¬ä¸€é¡µå¹¶ç¡®å®šæ€»é¡µæ•°
    logger.info("æ­£åœ¨è·å–ç¬¬1é¡µ...")
    first_page_content = get_page_content(base_url, logger)
    
    if not first_page_content:
        logger.error("âŒ æ— æ³•è·å–ç¬¬ä¸€é¡µå†…å®¹")
        return all_actions, stats
    
    total_pages = get_total_pages(first_page_content, logger)
    stats['total_pages'] = total_pages
    
    # å°è¯•ä½¿ç”¨pandasè§£æç¬¬ä¸€é¡µ
    first_page_actions = extract_actions_using_pandas(first_page_content, logger)
    
    # å¦‚æœpandaså¤±è´¥ï¼Œä½¿ç”¨lxmlä½œä¸ºå¤‡ç”¨
    if not first_page_actions:
        logger.info("pandasè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨lxml...")
        first_page_actions = extract_actions_using_lxml(first_page_content, logger)
    
    all_actions.extend(first_page_actions)
    
    # è·å–å‰©ä½™é¡µé¢
    for page in range(2, total_pages + 1):
        logger.info(f"æ­£åœ¨è·å–ç¬¬{page}é¡µ...")
        page_url = f"{base_url}?p={page}"  # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ ?p= è€Œä¸æ˜¯ ?page=
        page_content = get_page_content(page_url, logger)
        
        if page_content:
            page_actions = extract_actions_using_pandas(page_content, logger)
            if not page_actions:
                page_actions = extract_actions_using_lxml(page_content, logger)
            all_actions.extend(page_actions)
        else:
            logger.warning(f"âŒ æ— æ³•è·å–ç¬¬{page}é¡µå†…å®¹")
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)
    
    # ç»Ÿè®¡ä¿¡æ¯
    stats['total_actions'] = len(all_actions)
    
    for action in all_actions:
        # ç»Ÿè®¡ç‚¹èµæ•°
        likes_count = action.get('likes', 0)
        stats['total_likes'] += likes_count
        
        # ç»Ÿè®¡ä¸‹è½½æ•°
        downloads_count = action.get('downloads', 0)
        stats['total_downloads'] += downloads_count
    
    # è®¡ç®—å¹³å‡å€¼
    if stats['total_actions'] > 0:
        stats['avg_likes'] = round(stats['total_likes'] / stats['total_actions'], 2)
        stats['avg_downloads'] = round(stats['total_downloads'] / stats['total_actions'], 2)
    
    return all_actions, stats


def save_results(actions: List[Dict[str, any]], stats: Dict[str, any], user_id: str, logger: logging.Logger):
    """
    ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    
    Args:
        actions (List[Dict[str, any]]): åŠ¨ä½œåˆ—è¡¨
        stats (Dict[str, any]): ç»Ÿè®¡ä¿¡æ¯
        user_id (str): ç”¨æˆ·ID
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    """
    try:
        # ä¿å­˜è¯¦ç»†åŠ¨ä½œæ•°æ®
        actions_filename = f"user_actions_{user_id.replace('-', '_')}.json"
        with open(actions_filename, 'w', encoding='utf-8') as f:
            json.dump(actions, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… åŠ¨ä½œæ•°æ®å·²ä¿å­˜åˆ°: {actions_filename}")
        
        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        stats_filename = f"user_stats_{user_id.replace('-', '_')}.json"
        with open(stats_filename, 'w', encoding='utf-8') as f:
            json.dump(stats, f, ensure_ascii=False, indent=2)
        logger.info(f"âœ… ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {stats_filename}")
        
        # æ³¨æ„ï¼šä¸ä¿å­˜å•ç‹¬çš„CSVæ–‡ä»¶ï¼Œç»Ÿä¸€åœ¨æ¨èä½œè€…ç»Ÿè®¡ä¸­ä¿å­˜
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")


def print_summary(actions: List[Dict[str, any]], stats: Dict[str, any], logger: logging.Logger):
    """
    æ‰“å°ç»Ÿè®¡æ‘˜è¦
    
    Args:
        actions (List[Dict[str, any]]): åŠ¨ä½œåˆ—è¡¨
        stats (Dict[str, any]): ç»Ÿè®¡ä¿¡æ¯
        logger (logging.Logger): æ—¥å¿—è®°å½•å™¨
    """
    logger.info("=" * 60)
    logger.info("ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
    logger.info("=" * 60)
    logger.info(f"æ€»åŠ¨ä½œæ•°: {stats['total_actions']}")
    logger.info(f"æ€»é¡µæ•°: {stats['total_pages']}")
    logger.info(f"æ€»ç‚¹èµæ•°: {stats['total_likes']}")
    logger.info(f"æ€»ä¸‹è½½æ•°: {stats['total_downloads']}")
    logger.info(f"å¹³å‡ç‚¹èµæ•°: {stats['avg_likes']}")
    logger.info(f"å¹³å‡ä¸‹è½½æ•°: {stats['avg_downloads']}")
    
    logger.info("\nğŸ† ç‚¹èµæ•°æœ€é«˜çš„åŠ¨ä½œ:")
    top_actions = sorted(actions, key=lambda x: x.get('likes', 0), reverse=True)[:5]
    for i, action in enumerate(top_actions, 1):
        logger.info(f"  {i}. {action.get('name', 'Unknown')} - {action.get('likes', 0)} ç‚¹èµ")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    debug_mode = '--debug' in sys.argv
    if '--debug' in sys.argv:
        sys.argv.remove('--debug')
    
    # è®¾ç½®æ—¥å¿—è®°å½•å™¨
    logger = setup_logger(debug=debug_mode)
    
    logger.info("=" * 60)
    logger.info("GetQuickerç”¨æˆ·åŠ¨ä½œæ•°æ®ç»Ÿè®¡å·¥å…·")
    logger.info("=" * 60)
    
    # é»˜è®¤ç”¨æˆ·ID
    default_user_id = "113342-"
    
    # ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç”¨æˆ·IDæˆ–URL
    if len(sys.argv) > 1:
        user_input = sys.argv[1]
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯URL
        if user_input.startswith('http'):
            # ä»URLä¸­æå–ç”¨æˆ·ID
            if '/User/Actions/' in user_input:
                user_id = user_input.split('/User/Actions/')[-1].split('?')[0].split('#')[0]
            elif '/User/' in user_input:
                user_id = user_input.split('/User/')[-1].split('?')[0].split('#')[0]
            else:
                logger.error("âŒ æ— æ³•ä»URLä¸­æå–ç”¨æˆ·ID")
                return
            logger.info(f"ä»URLæå–ç”¨æˆ·ID: {user_id}")
        else:
            user_id = user_input
    else:
        user_id = default_user_id
        logger.info(f"ä½¿ç”¨é»˜è®¤ç”¨æˆ·ID: {user_id}")
    
    logger.info(f"ç›®æ ‡ç”¨æˆ·: {user_id}")
    logger.debug(f"è°ƒè¯•æ¨¡å¼: {'å¯ç”¨' if debug_mode else 'ç¦ç”¨'}")
    logger.info("-" * 60)
    
    # è·å–æ‰€æœ‰åŠ¨ä½œæ•°æ®
    logger.info("å¼€å§‹è·å–ç”¨æˆ·æ‰€æœ‰å…¬å¼€åŠ¨ä½œæ•°æ®...")
    actions, stats = get_all_user_actions(user_id, logger)
    
    if not actions:
        logger.error("âŒ æœªè·å–åˆ°ä»»ä½•åŠ¨ä½œæ•°æ®")
        return
    
    logger.info("-" * 60)
    
    # æ‰“å°ç»Ÿè®¡æ‘˜è¦
    print_summary(actions, stats, logger)
    
    logger.info("-" * 60)
    
    # ä¿å­˜ç»“æœ
    logger.info("æ­£åœ¨ä¿å­˜ç»“æœ...")
    save_results(actions, stats, user_id, logger)
    
    logger.info("-" * 60)
    logger.info("ğŸ‰ ä»»åŠ¡å®Œæˆï¼")
    logger.info("=" * 60)


if __name__ == "__main__":
    main()
